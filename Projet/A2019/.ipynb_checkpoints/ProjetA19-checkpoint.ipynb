{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur adjoint au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "Le projet a été développé à l'aide de Alice Breton, étudiante à la maîtrise en génie informatique. Elle a suivi le cours lors de la session Hiver 2019.\n",
    "\n",
    "\n",
    "\n",
    "# Projet : Débordement d'égouts\n",
    "\n",
    "La description du projet est disponible à l'adresse suivante :\n",
    "https://www.kaggle.com/t/a238b752c33a41d9803c2cdde6bfc929\n",
    "\n",
    "Ce calepin Jupyter de base permet de charger et de nettoyer les données fournies. La dernière section détaille la génération du fichier des prédictions afin de le soumettre sur Kaggle dans le bon format.\n",
    "\n",
    "Dans un premier temps, vous devrez récupérer l'archive *data.zip* sur Moodle. Ce dossier contient les fichiers suivants :\n",
    "- surverses.csv\n",
    "- precipitation.csv\n",
    "- ouvrages-surverses.csv\n",
    "- test.csv\n",
    "\n",
    "Veuillez le décompresser dans le répertoire de ce calepin.\n",
    "\n",
    "Le fichier *surverse.csv* répertorie s'il y a surverse (1) ou non (0) au cours de la journée pour les 170 ouvrages de débordement de 2013 à 2018 pour les mois de mai à octobre (inclusivement). Des renseignements additionnels sur les données sont disponibles à l'adresse suivante :\n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/debordement\n",
    "\n",
    "\n",
    "Le fichier *precipitation.csv* contient les précipitations horaires en dixième de *mm* enregistrées à 5 stations pluviométriques de 2013 à 2019 :\n",
    "- McTavish (7024745)\n",
    "- Ste-Anne-de-Bellevue (702FHL8)\n",
    "- Montreal/Pierre Elliott Trudeau Intl (702S006)\n",
    "- Montreal/St-Hubert (7027329)\n",
    "- L’Assomption (7014160)\n",
    "\n",
    "Plus d'informations sur les précipitations sont disponibles à l'adresse suivante :\n",
    "\n",
    "https://climat.meteo.gc.ca/climate_data/hourly_data_f.html?hlyRange=2008-01-08%7C2019-11-12&dlyRange=2002-12-23%7C2019-11-12&mlyRange=%7C&StationID=30165&Prov=QC&urlExtension=_f.html&searchType=stnName&optLimit=yearRange&StartYear=1840&EndYear=2019&selRowPerPage=25&Line=17&searchMethod=contains&Month=11&Day=12&txtStationName=montreal&timeframe=1&Year=2019\n",
    "\n",
    "Le fichier *ouvrages-surverses.csv* contient différentes caractéristiques des ouvrages de débordement. \n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/ouvrage-surverse\n",
    "\n",
    "Le fichier *test.csv* contient les ouvrages et les jours pour lesquels vous devez prédire s'il y a eu surverse (true) ou non (false). Notez que l'on s'intéresse ici à 5 ouvrages de débordement localisés tout autour de l'Ile de Montréal :\n",
    "- 3260-01D dans Rivière-des-Prairies \n",
    "- 3350-07D dans Ahunstic \n",
    "- 4240-01D dans Pointe-aux-Trembles \n",
    "- 4350-01D dans le Vieux-Montréal \n",
    "- 4380-01D dans Verdun\n",
    "\n",
    "#### Remarque\n",
    "\n",
    "Dans le projet, on ne s'intéresse qu'aux surverses occasionnées par les précipitations. On ignore les surverses occasionnées par \n",
    "- fonte de neige (F)\n",
    "- travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)\n",
    "\n",
    "On suppose que lorsqu'il n'y a pas de raison pour la surverse, il s'agit d'une surverse causée par les précipitations. Puisque Nous nous intéresserons uniquement aux surverses occasionnées par les précipitations liquides, nous ne considérons que les mois de mai à octobre inclusivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/surverses.csv\",missingstring=\"-99999\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.DATE) > 4, data) \n",
    "data = filter(row -> month(row.DATE) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data[:,:RAISON],\"Inconnue\")\n",
    "data[!,:RAISON] = raison\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>176,667 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr><tr><th>6</th><td>0642-01D</td><td>2013-05-06</td><td>0</td></tr><tr><th>7</th><td>0642-01D</td><td>2013-05-07</td><td>0</td></tr><tr><th>8</th><td>0642-01D</td><td>2013-05-08</td><td>0</td></tr><tr><th>9</th><td>0642-01D</td><td>2013-05-09</td><td>0</td></tr><tr><th>10</th><td>0642-01D</td><td>2013-05-10</td><td>0</td></tr><tr><th>11</th><td>0642-01D</td><td>2013-05-11</td><td>0</td></tr><tr><th>12</th><td>0642-01D</td><td>2013-05-12</td><td>0</td></tr><tr><th>13</th><td>0642-01D</td><td>2013-05-13</td><td>0</td></tr><tr><th>14</th><td>0642-01D</td><td>2013-05-14</td><td>0</td></tr><tr><th>15</th><td>0642-01D</td><td>2013-05-15</td><td>0</td></tr><tr><th>16</th><td>0642-01D</td><td>2013-05-16</td><td>0</td></tr><tr><th>17</th><td>0642-01D</td><td>2013-05-17</td><td>0</td></tr><tr><th>18</th><td>0642-01D</td><td>2013-05-18</td><td>0</td></tr><tr><th>19</th><td>0642-01D</td><td>2013-05-19</td><td>0</td></tr><tr><th>20</th><td>0642-01D</td><td>2013-05-20</td><td>0</td></tr><tr><th>21</th><td>0642-01D</td><td>2013-05-21</td><td>0</td></tr><tr><th>22</th><td>0642-01D</td><td>2013-05-22</td><td>0</td></tr><tr><th>23</th><td>0642-01D</td><td>2013-05-23</td><td>0</td></tr><tr><th>24</th><td>0642-01D</td><td>2013-05-24</td><td>0</td></tr><tr><th>25</th><td>0642-01D</td><td>2013-05-25</td><td>0</td></tr><tr><th>26</th><td>0642-01D</td><td>2013-05-26</td><td>0</td></tr><tr><th>27</th><td>0642-01D</td><td>2013-05-27</td><td>0</td></tr><tr><th>28</th><td>0642-01D</td><td>2013-05-28</td><td>0</td></tr><tr><th>29</th><td>0642-01D</td><td>2013-05-29</td><td>0</td></tr><tr><th>30</th><td>0642-01D</td><td>2013-05-30</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\t6 & 0642-01D & 2013-05-06 & 0 \\\\\n",
       "\t7 & 0642-01D & 2013-05-07 & 0 \\\\\n",
       "\t8 & 0642-01D & 2013-05-08 & 0 \\\\\n",
       "\t9 & 0642-01D & 2013-05-09 & 0 \\\\\n",
       "\t10 & 0642-01D & 2013-05-10 & 0 \\\\\n",
       "\t11 & 0642-01D & 2013-05-11 & 0 \\\\\n",
       "\t12 & 0642-01D & 2013-05-12 & 0 \\\\\n",
       "\t13 & 0642-01D & 2013-05-13 & 0 \\\\\n",
       "\t14 & 0642-01D & 2013-05-14 & 0 \\\\\n",
       "\t15 & 0642-01D & 2013-05-15 & 0 \\\\\n",
       "\t16 & 0642-01D & 2013-05-16 & 0 \\\\\n",
       "\t17 & 0642-01D & 2013-05-17 & 0 \\\\\n",
       "\t18 & 0642-01D & 2013-05-18 & 0 \\\\\n",
       "\t19 & 0642-01D & 2013-05-19 & 0 \\\\\n",
       "\t20 & 0642-01D & 2013-05-20 & 0 \\\\\n",
       "\t21 & 0642-01D & 2013-05-21 & 0 \\\\\n",
       "\t22 & 0642-01D & 2013-05-22 & 0 \\\\\n",
       "\t23 & 0642-01D & 2013-05-23 & 0 \\\\\n",
       "\t24 & 0642-01D & 2013-05-24 & 0 \\\\\n",
       "\t25 & 0642-01D & 2013-05-25 & 0 \\\\\n",
       "\t26 & 0642-01D & 2013-05-26 & 0 \\\\\n",
       "\t27 & 0642-01D & 2013-05-27 & 0 \\\\\n",
       "\t28 & 0642-01D & 2013-05-28 & 0 \\\\\n",
       "\t29 & 0642-01D & 2013-05-29 & 0 \\\\\n",
       "\t30 & 0642-01D & 2013-05-30 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "176667×3 DataFrame\n",
       "│ Row    │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│        │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├────────┼────────────┼────────────┼──────────┤\n",
       "│ 1      │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2      │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3      │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4      │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5      │ 0642-01D   │ 2013-05-05 │ 0        │\n",
       "│ 6      │ 0642-01D   │ 2013-05-06 │ 0        │\n",
       "│ 7      │ 0642-01D   │ 2013-05-07 │ 0        │\n",
       "│ 8      │ 0642-01D   │ 2013-05-08 │ 0        │\n",
       "│ 9      │ 0642-01D   │ 2013-05-09 │ 0        │\n",
       "│ 10     │ 0642-01D   │ 2013-05-10 │ 0        │\n",
       "⋮\n",
       "│ 176657 │ 4560-02D   │ 2018-10-21 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176658 │ 4560-02D   │ 2018-10-22 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176659 │ 4560-02D   │ 2018-10-23 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176660 │ 4560-02D   │ 2018-10-24 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176661 │ 4560-02D   │ 2018-10-25 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176662 │ 4560-02D   │ 2018-10-26 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176663 │ 4560-02D   │ 2018-10-27 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176664 │ 4560-02D   │ 2018-10-28 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176665 │ 4560-02D   │ 2018-10-29 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176666 │ 4560-02D   │ 2018-10-30 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176667 │ 4560-02D   │ 2018-10-31 │ \u001b[90mmissing\u001b[39m  │"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data) \n",
    "select!(data, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "first(data,5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverse_df = dropmissing(data, disallowmissing=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[7]:1\n",
      "└ @ Core In[7]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[7]:2\n",
      "└ @ Core In[7]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 161098"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n₁ = sum(x->x==1, surverse_df[:SURVERSE], dims=1) \n",
    "n₀ = sum(x->x==0, surverse_df[:SURVERSE], dims=1) \n",
    "n = n₀ + n₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"]\n",
    "surverse_df1 = filter(row-> row.NO_OUVRAGE == filtervals[1], surverse_df)\n",
    "surverse_df2 = filter(row-> row.NO_OUVRAGE == filtervals[2], surverse_df)\n",
    "surverse_df3 = filter(row-> row.NO_OUVRAGE == filtervals[3], surverse_df)\n",
    "surverse_df4 = filter(row-> row.NO_OUVRAGE == filtervals[4], surverse_df)\n",
    "surverse_df5 = filter(row-> row.NO_OUVRAGE == filtervals[5], surverse_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Int64,1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### on prend pour chaque ouvrage le nombre de fois ou il a eu surver et non\n",
    "n₁ = Int64[]\n",
    "n₀  = Int64[]\n",
    "n  = Int64[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[10]:1\n",
      "└ @ Core In[10]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[10]:3\n",
      "└ @ Core In[10]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 1097"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1₁ = sum(x->x==1, surverse_df1[:SURVERSE], dims=1) \n",
    "push!(n₁, n1₁[1])\n",
    "n1₀ = sum(x->x==0, surverse_df1[:SURVERSE], dims=1)  \n",
    "push!(n₀, n1₀[1])\n",
    "n1= n1₁[1] + n1₀[1]\n",
    "push!(n, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[11]:1\n",
      "└ @ Core In[11]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[11]:3\n",
      "└ @ Core In[11]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " 1097\n",
       "  729"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1₁ = sum(x->x==1, surverse_df2[:SURVERSE], dims=1) \n",
    "push!(n₁, n1₁[1])\n",
    "n1₀ = sum(x->x==0, surverse_df2[:SURVERSE], dims=1)  \n",
    "push!(n₀, n1₀[1])\n",
    "n1= n1₁[1] + n1₀[1]\n",
    "push!(n, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[12]:1\n",
      "└ @ Core In[12]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[12]:3\n",
      "└ @ Core In[12]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1097\n",
       "  729\n",
       " 1100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1₁ = sum(x->x==1, surverse_df3[:SURVERSE], dims=1) \n",
    "push!(n₁, n1₁[1])\n",
    "n1₀ = sum(x->x==0, surverse_df3[:SURVERSE], dims=1)  \n",
    "push!(n₀, n1₀[1])\n",
    "n1= n1₁[1] + n1₀[1]\n",
    "push!(n, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[13]:1\n",
      "└ @ Core In[13]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[13]:3\n",
      "└ @ Core In[13]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 1097\n",
       "  729\n",
       " 1100\n",
       " 1100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1₁ = sum(x->x==1, surverse_df4[:SURVERSE], dims=1) \n",
    "push!(n₁, n1₁[1])\n",
    "n1₀ = sum(x->x==0, surverse_df4[:SURVERSE], dims=1)  \n",
    "push!(n₀, n1₀[1])\n",
    "n1= n1₁[1] + n1₀[1]\n",
    "push!(n, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[14]:1\n",
      "└ @ Core In[14]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[14]:3\n",
      "└ @ Core In[14]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Int64,1}:\n",
       " 1097\n",
       "  729\n",
       " 1100\n",
       " 1100\n",
       " 1103"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1₁ = sum(x->x==1, surverse_df5[:SURVERSE], dims=1) \n",
    "push!(n₁, n1₁[1])\n",
    "n1₀ = sum(x->x==0, surverse_df5[:SURVERSE], dims=1)  \n",
    "push!(n₀, n1₀[1])\n",
    "n1= n1₁[1] + n1₀[1]\n",
    "push!(n, n1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-01-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-01-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-01-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-01-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-01-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-01-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-01-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-01-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-01-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-01-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-01-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-01-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-01-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-01-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-01-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter(row -> month(row.date) > 4, data) \n",
    "data = filter(row -> month(row.date) < 11, data) \n",
    "data = filter(row -> year(row.date) == 2019, data) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire\n",
    "\n",
    "Cette section consitue une analyse exploratoire superficielle permettant de voir s'il existe un lien entre les précipitations et les surverses.\n",
    "\n",
    "Prenons arbitrairement l'ouvrage de débordement près du Bota-Bota (4350-01D). La station météorologique la plus proche est McTavish. Prenons deux variables explicatives simple :\n",
    "- la somme journalière des précipitations\n",
    "- le taux horaire maximum journalier de précipitations\n",
    "\n",
    "#### Calcul de la quantité journalière de précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>79</td><td>52</td><td>58</td><td>47</td><td>68</td></tr><tr><th>2</th><td>2019-05-02</td><td>26</td><td>19</td><td>15</td><td>13</td><td>17</td></tr><tr><th>3</th><td>2019-05-03</td><td>34</td><td>27</td><td>34</td><td>31</td><td>44</td></tr><tr><th>4</th><td>2019-05-04</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>2019-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 79 & 52 & 58 & 47 & 68 \\\\\n",
       "\t2 & 2019-05-02 & 26 & 19 & 15 & 13 & 17 \\\\\n",
       "\t3 & 2019-05-03 & 34 & 27 & 34 & 31 & 44 \\\\\n",
       "\t4 & 2019-05-04 & 2 & 0 & 0 & 2 & 0 \\\\\n",
       "\t5 & 2019-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-05-01 │ 79       │ 52       │ 58         │ 47      │ 68       │\n",
       "│ 2   │ 2019-05-02 │ 26       │ 19       │ 15         │ 13      │ 17       │\n",
       "│ 3   │ 2019-05-03 │ 34       │ 27       │ 34         │ 31      │ 44       │\n",
       "│ 4   │ 2019-05-04 │ 2        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 5   │ 2019-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_sum = by(data, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum)\n",
    "first(pcp_sum ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j=1:size(pcp_sum,1)\n",
    "    means = 0\n",
    "    sum = 0\n",
    "    alo = names(pcp_sum)\n",
    "    for col in alo\n",
    "        if col != alo[1]\n",
    "            if !ismissing(pcp_sum[j, col]) \n",
    "                sum = sum +1\n",
    "                means = means + pcp_sum[j, col]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if sum != 0\n",
    "        means = means / sum\n",
    "    end\n",
    "    for col in alo\n",
    "        if ismissing(pcp_sum[j, col]) && col != alo[1]\n",
    "            tests = floor(means)\n",
    "            pcp_sum[j, col] = tests\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction du taux horaire journalier maximum des précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>24</td><td>24</td><td>15</td><td>21</td><td>22</td></tr><tr><th>2</th><td>2019-05-02</td><td>12</td><td>7</td><td>7</td><td>8</td><td>10</td></tr><tr><th>3</th><td>2019-05-03</td><td>12</td><td>11</td><td>14</td><td>14</td><td>15</td></tr><tr><th>4</th><td>2019-05-04</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>2019-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 24 & 24 & 15 & 21 & 22 \\\\\n",
       "\t2 & 2019-05-02 & 12 & 7 & 7 & 8 & 10 \\\\\n",
       "\t3 & 2019-05-03 & 12 & 11 & 14 & 14 & 15 \\\\\n",
       "\t4 & 2019-05-04 & 2 & 0 & 0 & 2 & 0 \\\\\n",
       "\t5 & 2019-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-05-01 │ 24       │ 24       │ 15         │ 21      │ 22       │\n",
       "│ 2   │ 2019-05-02 │ 12       │ 7        │ 7          │ 8       │ 10       │\n",
       "│ 3   │ 2019-05-03 │ 12       │ 11       │ 14         │ 14      │ 15       │\n",
       "│ 4   │ 2019-05-04 │ 2        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 5   │ 2019-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_max = by(data, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j=1:size(pcp_max,1)\n",
    "    means = 0\n",
    "    sum = 0\n",
    "    alo = names(pcp_max)\n",
    "    for col in alo\n",
    "        if col != alo[1]\n",
    "            if !ismissing(pcp_max[j, col]) \n",
    "                sum = sum +1\n",
    "                means = means + pcp_max[j, col]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if sum != 0\n",
    "        means = means / sum\n",
    "    end\n",
    "    for col in alo\n",
    "        if ismissing(pcp_max[j, col]) && col != alo[1]\n",
    "            tests = floor(means)\n",
    "            pcp_max[j, col] = tests\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>184 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>24</td><td>24</td><td>15</td><td>21</td><td>22</td></tr><tr><th>2</th><td>2019-05-02</td><td>12</td><td>7</td><td>7</td><td>8</td><td>10</td></tr><tr><th>3</th><td>2019-05-03</td><td>12</td><td>11</td><td>14</td><td>14</td><td>15</td></tr><tr><th>4</th><td>2019-05-04</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>2019-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>2019-05-06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>2019-05-07</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>8</th><td>2019-05-08</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>2019-05-09</td><td>45</td><td>26</td><td>55</td><td>43</td><td>32</td></tr><tr><th>10</th><td>2019-05-10</td><td>66</td><td>48</td><td>50</td><td>48</td><td>50</td></tr><tr><th>11</th><td>2019-05-11</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>12</th><td>2019-05-12</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>13</th><td>2019-05-13</td><td>18</td><td>14</td><td>0</td><td>9</td><td>5</td></tr><tr><th>14</th><td>2019-05-14</td><td>22</td><td>21</td><td>25</td><td>18</td><td>15</td></tr><tr><th>15</th><td>2019-05-15</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>16</th><td>2019-05-16</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>17</th><td>2019-05-17</td><td>3</td><td>5</td><td>0</td><td>3</td><td>5</td></tr><tr><th>18</th><td>2019-05-18</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>19</th><td>2019-05-19</td><td>23</td><td>32</td><td>16</td><td>27</td><td>25</td></tr><tr><th>20</th><td>2019-05-20</td><td>40</td><td>5</td><td>27</td><td>51</td><td>38</td></tr><tr><th>21</th><td>2019-05-21</td><td>0</td><td>0</td><td>3</td><td>2</td><td>0</td></tr><tr><th>22</th><td>2019-05-22</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>23</th><td>2019-05-23</td><td>117</td><td>117</td><td>186</td><td>66</td><td>99</td></tr><tr><th>24</th><td>2019-05-24</td><td>9</td><td>9</td><td>12</td><td>6</td><td>12</td></tr><tr><th>25</th><td>2019-05-25</td><td>0</td><td>2</td><td>7</td><td>2</td><td>2</td></tr><tr><th>26</th><td>2019-05-26</td><td>3</td><td>8</td><td>21</td><td>3</td><td>5</td></tr><tr><th>27</th><td>2019-05-27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>28</th><td>2019-05-28</td><td>3</td><td>3</td><td>0</td><td>8</td><td>3</td></tr><tr><th>29</th><td>2019-05-29</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>30</th><td>2019-05-30</td><td>7</td><td>9</td><td>10</td><td>9</td><td>10</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 24 & 24 & 15 & 21 & 22 \\\\\n",
       "\t2 & 2019-05-02 & 12 & 7 & 7 & 8 & 10 \\\\\n",
       "\t3 & 2019-05-03 & 12 & 11 & 14 & 14 & 15 \\\\\n",
       "\t4 & 2019-05-04 & 2 & 0 & 0 & 2 & 0 \\\\\n",
       "\t5 & 2019-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 2019-05-06 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 2019-05-07 & 3 & 0 & 0 & 0 & 0 \\\\\n",
       "\t8 & 2019-05-08 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t9 & 2019-05-09 & 45 & 26 & 55 & 43 & 32 \\\\\n",
       "\t10 & 2019-05-10 & 66 & 48 & 50 & 48 & 50 \\\\\n",
       "\t11 & 2019-05-11 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t12 & 2019-05-12 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t13 & 2019-05-13 & 18 & 14 & 0 & 9 & 5 \\\\\n",
       "\t14 & 2019-05-14 & 22 & 21 & 25 & 18 & 15 \\\\\n",
       "\t15 & 2019-05-15 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t16 & 2019-05-16 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t17 & 2019-05-17 & 3 & 5 & 0 & 3 & 5 \\\\\n",
       "\t18 & 2019-05-18 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t19 & 2019-05-19 & 23 & 32 & 16 & 27 & 25 \\\\\n",
       "\t20 & 2019-05-20 & 40 & 5 & 27 & 51 & 38 \\\\\n",
       "\t21 & 2019-05-21 & 0 & 0 & 3 & 2 & 0 \\\\\n",
       "\t22 & 2019-05-22 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t23 & 2019-05-23 & 117 & 117 & 186 & 66 & 99 \\\\\n",
       "\t24 & 2019-05-24 & 9 & 9 & 12 & 6 & 12 \\\\\n",
       "\t25 & 2019-05-25 & 0 & 2 & 7 & 2 & 2 \\\\\n",
       "\t26 & 2019-05-26 & 3 & 8 & 21 & 3 & 5 \\\\\n",
       "\t27 & 2019-05-27 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t28 & 2019-05-28 & 3 & 3 & 0 & 8 & 3 \\\\\n",
       "\t29 & 2019-05-29 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t30 & 2019-05-30 & 7 & 9 & 10 & 9 & 10 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "184×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-05-01 │ 24       │ 24       │ 15         │ 21      │ 22       │\n",
       "│ 2   │ 2019-05-02 │ 12       │ 7        │ 7          │ 8       │ 10       │\n",
       "│ 3   │ 2019-05-03 │ 12       │ 11       │ 14         │ 14      │ 15       │\n",
       "│ 4   │ 2019-05-04 │ 2        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 5   │ 2019-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 6   │ 2019-05-06 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 7   │ 2019-05-07 │ 3        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 8   │ 2019-05-08 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 9   │ 2019-05-09 │ 45       │ 26       │ 55         │ 43      │ 32       │\n",
       "│ 10  │ 2019-05-10 │ 66       │ 48       │ 50         │ 48      │ 50       │\n",
       "⋮\n",
       "│ 174 │ 2019-10-21 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 175 │ 2019-10-22 │ 31       │ 37       │ 37         │ 53      │ 28       │\n",
       "│ 176 │ 2019-10-23 │ 58       │ 50       │ 50         │ 28      │ 65       │\n",
       "│ 177 │ 2019-10-24 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 178 │ 2019-10-25 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 179 │ 2019-10-26 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 180 │ 2019-10-27 │ 102      │ 94       │ 94         │ 98      │ 83       │\n",
       "│ 181 │ 2019-10-28 │ 3        │ 2        │ 2          │ 2       │ 2        │\n",
       "│ 182 │ 2019-10-29 │ 0        │ 0        │ 0          │ 0       │ 2        │\n",
       "│ 183 │ 2019-10-30 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 184 │ 2019-10-31 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inclusion dans un dataframe de ces deux variables explicatives potentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage = \"4350-01D\"\n",
    "moyenneSumSurverses = Float64[]\n",
    "moyenneMaxSurverses = Float64[]\n",
    "varianceSumSurverses = Float64[];\n",
    "varianceMaxSurverses = Float64[];\n",
    "\n",
    "moyenneSumNonSurverses = Float64[]\n",
    "moyenneMaxNonSurverses = Float64[]\n",
    "varianceSumNonSurverses = Float64[]\n",
    "varianceMaxNonSurverses = Float64[]\n",
    "for j=1:size(filtervals,1)\n",
    "    dfSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==1, surverse_df)\n",
    "    dfNonSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==0, surverse_df)\n",
    "\n",
    "\n",
    "    moyenneSumSurverse = 0;\n",
    "    moyenneMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneSumSurverse = moyenneSumSurverse +  pcp_sum[ind,:McTavish]\n",
    "        \n",
    "        ind = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneMaxSurverse = moyenneMaxSurverse +  pcp_max[ind,:McTavish]\n",
    "    end\n",
    "    moyenneSumSurverse = moyenneSumSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneSumSurverses, moyenneSumSurverse)\n",
    "    moyenneMaxSurverse = moyenneMaxSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneMaxSurverses, moyenneMaxSurverse)\n",
    "    \n",
    "    moyenneSumNonSurverse = 0;\n",
    "    moyenneMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneSumNonSurverse = moyenneSumNonSurverse +  pcp_sum[ind,:McTavish]\n",
    "        \n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneMaxNonSurverse = moyenneMaxNonSurverse +  pcp_max[ind,:McTavish]\n",
    "    end\n",
    "    moyenneSumNonSurverse = moyenneSumNonSurverse / size(dfNonSurverse,1)\n",
    "    push!(moyenneSumNonSurverses, moyenneSumNonSurverse)\n",
    "    moyenneMaxNonSurverse = moyenneMaxNonSurverse / size(dfNonSurverse,1)\n",
    "    push!(moyenneMaxNonSurverses, moyenneMaxNonSurverse)\n",
    "    \n",
    "    \n",
    "    #### maintenant la variance\n",
    "    varianceSumSurverse = 0;\n",
    "    varianceMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceSumSurverse = varianceSumSurverse +  (pcp_sum[ind,:McTavish]-moyenneSumSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceMaxSurverse = varianceMaxSurverse +  (pcp_max[ind,:McTavish]-moyenneMaxSurverse)^2\n",
    "    end\n",
    "    varianceSumSurverse = varianceSumSurverse / size(dfSurverse,1)\n",
    "    push!(varianceSumSurverses, varianceSumSurverse)\n",
    "    varianceMaxSurverse = varianceMaxSurverse / size(dfSurverse,1)\n",
    "    push!(varianceMaxSurverses, varianceMaxSurverse)\n",
    "    \n",
    "    varianceSumNonSurverse = 0;\n",
    "    varianceMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceSumNonSurverse = varianceSumNonSurverse +  (pcp_sum[ind,:McTavish]-moyenneSumNonSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceMaxNonSurverse = varianceMaxNonSurverse +  (pcp_max[ind,:McTavish]-moyenneMaxNonSurverse)^2\n",
    "    end\n",
    "    varianceSumNonSurverse = varianceSumNonSurverse / size(dfNonSurverse,1)\n",
    "    push!(varianceSumNonSurverses, varianceSumNonSurverse)\n",
    "    varianceMaxNonSurverse = varianceMaxNonSurverse / size(dfNonSurverse,1)\n",
    "    push!(varianceMaxNonSurverses, varianceMaxNonSurverse)\n",
    "   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 20596.022747849704\n",
       " 15506.004930606281\n",
       " 27187.445914723798\n",
       " 21075.098072562352\n",
       " 21825.605867346938"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que la somme des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = evalmapping(::DataFrame, ::Symbol) at dataframes.jl:96\n",
      "└ @ Gadfly C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\dataframes.jl:96\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: column name :SUM not found in the data frame",
     "output_type": "error",
     "traceback": [
      "ArgumentError: column name :SUM not found in the data frame",
      "",
      "Stacktrace:",
      " [1] getindex(::DataFrame, ::typeof(!), ::Symbol) at C:\\Users\\elie_\\.julia\\packages\\DataFrames\\yH0f6\\src\\other\\index.jl:238",
      " [2] getindex(::DataFrame, ::Symbol) at .\\deprecated.jl:67",
      " [3] evalmapping(::DataFrame, ::Symbol) at C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\dataframes.jl:96",
      " [4] _evalmapping!(::Dict{Symbol,Any}, ::DataFrame, ::Gadfly.Data) at C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\mapping.jl:207",
      " [5] evalmapping!(::Dict{Symbol,Any}, ::DataFrame, ::Gadfly.Data) at C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\mapping.jl:236",
      " [6] plot(::DataFrame, ::Dict{Symbol,Symbol}, ::Type{Gadfly.Geom.BoxplotGeometry}) at C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\Gadfly.jl:330",
      " [7] #plot#71 at C:\\Users\\elie_\\.julia\\packages\\Gadfly\\1wgcD\\src\\Gadfly.jl:292 [inlined]",
      " [8] (::Gadfly.var\"#kw##plot\")(::NamedTuple{(:x, :y),Tuple{Symbol,Symbol}}, ::typeof(plot), ::DataFrame, ::Type{Gadfly.Geom.BoxplotGeometry}) at .\\none:0",
      " [9] top-level scope at In[43]:1"
     ]
    }
   ],
   "source": [
    "plot(df, x=:SURVERSE, y=:SUM, Geom.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que le maximum journalier des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[26]:1"
     ]
    }
   ],
   "source": [
    "plot(df, x=:SURVERSE, y=:MAX, Geom.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du fichier de prédictions pour soumettre sur Kaggle\n",
    "\n",
    "Dans ce cas-ci, nous prédirons une surverse avec une probabilité de 1/2 sans considérer aucune variable explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th></tr><tr><th></th><th>String</th><th>Date</th></tr></thead><tbody><p>5 rows × 2 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& NO\\_OUVRAGE & DATE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×2 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼────────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = CSV.read(\"data/test.csv\")\n",
    "first(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"]\n",
    "\n",
    "    ind = findfirst(filtervals[:] .== \"3260-01D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283-element Array{String,1}:\n",
       " \"3260-01D_2019-05-02\"\n",
       " \"3260-01D_2019-05-09\"\n",
       " \"3260-01D_2019-05-10\"\n",
       " \"3260-01D_2019-05-15\"\n",
       " \"3260-01D_2019-05-20\"\n",
       " \"3260-01D_2019-05-23\"\n",
       " \"3260-01D_2019-05-24\"\n",
       " \"3260-01D_2019-05-26\"\n",
       " \"3260-01D_2019-05-30\"\n",
       " \"3350-07D_2019-05-01\"\n",
       " \"3350-07D_2019-05-02\"\n",
       " \"3350-07D_2019-05-08\"\n",
       " \"3350-07D_2019-05-09\"\n",
       " ⋮                    \n",
       " \"4380-01D_2019-09-01\"\n",
       " \"4380-01D_2019-09-02\"\n",
       " \"4380-01D_2019-09-04\"\n",
       " \"4380-01D_2019-09-05\"\n",
       " \"4380-01D_2019-09-12\"\n",
       " \"4380-01D_2019-09-13\"\n",
       " \"4380-01D_2019-09-16\"\n",
       " \"4380-01D_2019-09-22\"\n",
       " \"4380-01D_2019-09-26\"\n",
       " \"4380-01D_2019-09-28\"\n",
       " \"4380-01D_2019-09-29\"\n",
       " \"4380-01D_2019-09-30\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surverse = bool[]\n",
    "\n",
    "for j=1:size(filtervals,1)\n",
    "    indproba = findfirst(filtervals[:] .== test[i,:NO_OUVRAGE])\n",
    "    ind = findfirst(pcp_sum[:,:date] .== test[i,:DATE])\n",
    "    sum = pcp_sum[ind,:McTavish]\n",
    "    ind = findfirst(pcp_max[:,:date] .== test[i,:DATE])\n",
    "    max = pcp_max[ind,:McTavish]\n",
    "   \n",
    "    \n",
    "end\n",
    "# Pour chacune des lignes du fichier test, comportant un ouvrage et une date, une prédiction est requise.\n",
    "# Dans ce cas-ci, utilisons une prédiction les plus naîve. \n",
    "# On prédit avec une chance sur deux qu'il y ait surverse, sans utiliser de variables explicatives\n",
    "n = size(test,1)\n",
    "surverse = rand(n) .> .5\n",
    "\n",
    "\n",
    "# Création du fichier sampleSubmission.csv pour soumettre sur Kaggle\n",
    "ID = test[:,:NO_OUVRAGE].*\"_\".*string.(test[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=surverse)\n",
    "CSV.write(\"sampleSubmission.csv\",sampleSubmission)\n",
    "\n",
    "# Vous pouvez par la suite déposer le fichier sampleSubmission.csv sur Kaggle.\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
