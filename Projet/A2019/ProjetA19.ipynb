{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "\n",
    "# Projet final : Débordement d'égouts\n",
    "### Équipe 17 : Elie Rouphael, Souhaila Mellouk, Thien-Kim Luu, Mourad Younes, Lynn Chararbsissy \n",
    "Remis le vendredi 20 décembre\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table des matières\n",
    "\n",
    "\n",
    "-  [1. Introduction](#1.-Introduction)\n",
    "\n",
    "-  [2. Chargement des données et nettoyage préliminaire](#2.-Chargement-des-données-et-nettoyage-préliminaire)\n",
    "    - [2.1. Chargement des surverses](#2.1.-Chargement-des-surverses)\n",
    "    - [2.2. Nettoyage des données sur les surverses](#2.2.-Nettoyage-des-données-sur-les-surverses)\n",
    "    - [2.3. Chargement des précipitations](#2.3.-Chargement-des-précipitations)\n",
    "    - [2.4. Nettoyage des données sur les précipitations](#2.4.-Nettoyage-des-données-sur-les-précipitations)\n",
    "    \n",
    "- [3. Analyse exploratoire selon la classification bayésienne naïve](#3.-Analyse-exploratoire-selon-la-classification-bayésienne-naïve)\n",
    "    - [3.1. Distances entre les stations et les ouvrages](#3.1.-Distances-entre-les-stations-et-les-ouvrages)\n",
    "     \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Le but de ce projet consiste à déterminer les caractéristiques des événements pluvieux susceptibles de générer des surverses sur le territoire de la Ville de Montréal. Il s'agit d'établir le lien entre les événements pluvieux et les surverses dues aux précipitations. On suppose que lorsqu'il n'y a pas de raison pour la surverse, il s'agit d'une surverse causée par les précipitations. Puisque nous nous intéresserons uniquement aux surverses occasionnées par les précipitations liquides, nous ne considérons que les mois de mai à octobre inclusivement.\n",
    "\n",
    "La description du projet est disponible à l'adresse suivante :\n",
    "https://www.kaggle.com/t/a238b752c33a41d9803c2cdde6bfc929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/surverses.csv\",missingstring=\"-99999\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.DATE) > 4, data) \n",
    "data = filter(row -> month(row.DATE) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data[:,:RAISON],\"Inconnue\")\n",
    "data[!,:RAISON] = raison\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>176,667 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr><tr><th>6</th><td>0642-01D</td><td>2013-05-06</td><td>0</td></tr><tr><th>7</th><td>0642-01D</td><td>2013-05-07</td><td>0</td></tr><tr><th>8</th><td>0642-01D</td><td>2013-05-08</td><td>0</td></tr><tr><th>9</th><td>0642-01D</td><td>2013-05-09</td><td>0</td></tr><tr><th>10</th><td>0642-01D</td><td>2013-05-10</td><td>0</td></tr><tr><th>11</th><td>0642-01D</td><td>2013-05-11</td><td>0</td></tr><tr><th>12</th><td>0642-01D</td><td>2013-05-12</td><td>0</td></tr><tr><th>13</th><td>0642-01D</td><td>2013-05-13</td><td>0</td></tr><tr><th>14</th><td>0642-01D</td><td>2013-05-14</td><td>0</td></tr><tr><th>15</th><td>0642-01D</td><td>2013-05-15</td><td>0</td></tr><tr><th>16</th><td>0642-01D</td><td>2013-05-16</td><td>0</td></tr><tr><th>17</th><td>0642-01D</td><td>2013-05-17</td><td>0</td></tr><tr><th>18</th><td>0642-01D</td><td>2013-05-18</td><td>0</td></tr><tr><th>19</th><td>0642-01D</td><td>2013-05-19</td><td>0</td></tr><tr><th>20</th><td>0642-01D</td><td>2013-05-20</td><td>0</td></tr><tr><th>21</th><td>0642-01D</td><td>2013-05-21</td><td>0</td></tr><tr><th>22</th><td>0642-01D</td><td>2013-05-22</td><td>0</td></tr><tr><th>23</th><td>0642-01D</td><td>2013-05-23</td><td>0</td></tr><tr><th>24</th><td>0642-01D</td><td>2013-05-24</td><td>0</td></tr><tr><th>25</th><td>0642-01D</td><td>2013-05-25</td><td>0</td></tr><tr><th>26</th><td>0642-01D</td><td>2013-05-26</td><td>0</td></tr><tr><th>27</th><td>0642-01D</td><td>2013-05-27</td><td>0</td></tr><tr><th>28</th><td>0642-01D</td><td>2013-05-28</td><td>0</td></tr><tr><th>29</th><td>0642-01D</td><td>2013-05-29</td><td>0</td></tr><tr><th>30</th><td>0642-01D</td><td>2013-05-30</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\t6 & 0642-01D & 2013-05-06 & 0 \\\\\n",
       "\t7 & 0642-01D & 2013-05-07 & 0 \\\\\n",
       "\t8 & 0642-01D & 2013-05-08 & 0 \\\\\n",
       "\t9 & 0642-01D & 2013-05-09 & 0 \\\\\n",
       "\t10 & 0642-01D & 2013-05-10 & 0 \\\\\n",
       "\t11 & 0642-01D & 2013-05-11 & 0 \\\\\n",
       "\t12 & 0642-01D & 2013-05-12 & 0 \\\\\n",
       "\t13 & 0642-01D & 2013-05-13 & 0 \\\\\n",
       "\t14 & 0642-01D & 2013-05-14 & 0 \\\\\n",
       "\t15 & 0642-01D & 2013-05-15 & 0 \\\\\n",
       "\t16 & 0642-01D & 2013-05-16 & 0 \\\\\n",
       "\t17 & 0642-01D & 2013-05-17 & 0 \\\\\n",
       "\t18 & 0642-01D & 2013-05-18 & 0 \\\\\n",
       "\t19 & 0642-01D & 2013-05-19 & 0 \\\\\n",
       "\t20 & 0642-01D & 2013-05-20 & 0 \\\\\n",
       "\t21 & 0642-01D & 2013-05-21 & 0 \\\\\n",
       "\t22 & 0642-01D & 2013-05-22 & 0 \\\\\n",
       "\t23 & 0642-01D & 2013-05-23 & 0 \\\\\n",
       "\t24 & 0642-01D & 2013-05-24 & 0 \\\\\n",
       "\t25 & 0642-01D & 2013-05-25 & 0 \\\\\n",
       "\t26 & 0642-01D & 2013-05-26 & 0 \\\\\n",
       "\t27 & 0642-01D & 2013-05-27 & 0 \\\\\n",
       "\t28 & 0642-01D & 2013-05-28 & 0 \\\\\n",
       "\t29 & 0642-01D & 2013-05-29 & 0 \\\\\n",
       "\t30 & 0642-01D & 2013-05-30 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "176667×3 DataFrame\n",
       "│ Row    │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│        │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├────────┼────────────┼────────────┼──────────┤\n",
       "│ 1      │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2      │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3      │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4      │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5      │ 0642-01D   │ 2013-05-05 │ 0        │\n",
       "│ 6      │ 0642-01D   │ 2013-05-06 │ 0        │\n",
       "│ 7      │ 0642-01D   │ 2013-05-07 │ 0        │\n",
       "│ 8      │ 0642-01D   │ 2013-05-08 │ 0        │\n",
       "│ 9      │ 0642-01D   │ 2013-05-09 │ 0        │\n",
       "│ 10     │ 0642-01D   │ 2013-05-10 │ 0        │\n",
       "⋮\n",
       "│ 176657 │ 4560-02D   │ 2018-10-21 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176658 │ 4560-02D   │ 2018-10-22 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176659 │ 4560-02D   │ 2018-10-23 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176660 │ 4560-02D   │ 2018-10-24 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176661 │ 4560-02D   │ 2018-10-25 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176662 │ 4560-02D   │ 2018-10-26 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176663 │ 4560-02D   │ 2018-10-27 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176664 │ 4560-02D   │ 2018-10-28 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176665 │ 4560-02D   │ 2018-10-29 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176666 │ 4560-02D   │ 2018-10-30 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176667 │ 4560-02D   │ 2018-10-31 │ \u001b[90mmissing\u001b[39m  │"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data) \n",
    "select!(data, [:NO_OUVRAGE, :DATE, :SURVERSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverse_df = dropmissing(data, disallowmissing=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[734]:1\n",
      "└ @ Core In[734]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[734]:2\n",
      "└ @ Core In[734]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 161098"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n₁ = sum(x->x==1, surverse_df[:SURVERSE], dims=1) \n",
    "n₀ = sum(x->x==0, surverse_df[:SURVERSE], dims=1) \n",
    "n = n₀ + n₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"]\n",
    "surverse_df1 = filter(row-> row.NO_OUVRAGE == filtervals[1], surverse_df)\n",
    "surverse_df2 = filter(row-> row.NO_OUVRAGE == filtervals[2], surverse_df)\n",
    "surverse_df3 = filter(row-> row.NO_OUVRAGE == filtervals[3], surverse_df)\n",
    "surverse_df4 = filter(row-> row.NO_OUVRAGE == filtervals[4], surverse_df)\n",
    "surverse_df5 = filter(row-> row.NO_OUVRAGE == filtervals[5], surverse_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### on prend pour chaque ouvrage le nombre de fois ou il a eu surver et non\n",
    "n₁ = Int64[]\n",
    "n₀  = Int64[]\n",
    "n  = Int64[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function findSurverseCount(surverse_df1)\n",
    "    n1₁ = sum(x->x==1, surverse_df1, dims=1) \n",
    "    push!(n₁, n1₁[1])\n",
    "    n1₀ = sum(x->x==0, surverse_df1, dims=1)  \n",
    "    push!(n₀, n1₀[1])\n",
    "    n1= n1₁[1] + n1₀[1]\n",
    "    push!(n, n1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findSurverseCount(surverse_df1[:SURVERSE]);\n",
    "findSurverseCount(surverse_df2[:SURVERSE]);\n",
    "findSurverseCount(surverse_df3[:SURVERSE]);\n",
    "findSurverseCount(surverse_df4[:SURVERSE]);\n",
    "findSurverseCount(surverse_df5[:SURVERSE]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databefore = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(databefore, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(databefore,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons extracté dans \"data\" toutes les données venant du moi de mai jusqu'au moi d'octobre. Nous avons aussi crée une\n",
    "variable \"databefore\", qui va surtout servir pour les jours ou il n'a pas plu beaucoup mais il y'a eu quand meme une surverse. Nous avons choisis d'extracter à partir du mois d'avril, puisqu'il existe quand même la possibilité que le premier mai, il y'a \n",
    "surverse, même s'il n'a pas plu, et dans ce cas il faudra vérifier le jour précédent, soit le 30 Avril."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter(row -> month(row.date) > 4, data) \n",
    "data = filter(row -> month(row.date) < 11, data) \n",
    "databefore = filter(row -> month(row.date) > 3, databefore)\n",
    "databefore = filter(row -> month(row.date) < 11, databefore) \n",
    "databefore = filter(row -> row.heure >= 19, databefore) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillWithMean() va principalement s'occuper à remplacer tous les missing values par la moyenne des autres colonnes de \n",
    "précipitation. Dans le cas ou toutes les valeurs d'une date spécifique sont égales a missing, elle va les remplacer \n",
    "par un zéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fillWithMean(table)\n",
    "    \n",
    "    for j=1:size(table,1)\n",
    "        means = 0\n",
    "        sum = 0\n",
    "        columnsname = names(table)\n",
    "        for col in columnsname\n",
    "            if col != columnsname[1]\n",
    "                if !ismissing(table[j, col]) \n",
    "                    sum = sum +1\n",
    "                    means = means + table[j, col]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        if sum != 0\n",
    "            means = means / sum\n",
    "        end\n",
    "        for col in columnsname\n",
    "            if ismissing(table[j, col]) && col != columnsname[1]\n",
    "                table[j, col] = floor(means)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillWithMean(data)\n",
    "fillWithMean(databefore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(data, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum);\n",
    "first(pcp_sum ,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(data, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sumBefore = by(databefore, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum);\n",
    "first(pcp_sum ,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_maxBefore = by(databefore, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse exploratoire selon la classification bayésienne naïve\n",
    "\n",
    "Cette section constitue une analyse exploratoire permettant de voir s'il existe un lien entre les précipitations et les surverses.\n",
    "\n",
    "On choisit d'utiliser la classification bayésienne naïve. Cette méthode étant simple, rapide, ne nécessite pas beaucoup de données et fonctionne bien lorsqu'il y a peu de dépendance entre les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**findMeanOfAllColumn** mets dans une colonne la moyenne de toutes les colonnes de la table passée en paramètres\n",
    "\n",
    "@params une table \n",
    "\n",
    "@return une table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function findMeanOfAllColumn(table)\n",
    "    p = DataFrame(name =Float64[])\n",
    "    for j=1:size(table,1)\n",
    "        alo = names(table)\n",
    "        means = 0\n",
    "        sum = 0\n",
    "        for col in alo\n",
    "            if col != alo[1]\n",
    "                if !ismissing(table[j, col]) \n",
    "                    sum = sum +1\n",
    "                    means = means + table[j, col]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(p, means/sum)\n",
    "    end\n",
    "    table = DataFrame(date = table[:date]; name =p[:name]);\n",
    "    return table\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"pcp_max_before.csv\",pcp_max)\n",
    "CSV.write(\"pcp_sum_before.csv\",pcp_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Distances entre les stations et les ouvrages\n",
    "\n",
    "Chaque ouvrage se trouve à proximité de différentes stations pluviométriques, on décide donc de comparer les distances entre ces dernières et nos 5 ouvrages.\n",
    "\n",
    "**Tableau 1. Distances entre les stations pluviométriques et les lieux des ouvrages**\n",
    "\n",
    "|  | McTavish | Ste-Anne-de-Bellevue | Montréal/Pierre Elliott Trudeau Intl | Montréal/St-Hubert | L’Assomption |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| Rivière-des-Prairies | 16,56 km | 37,31 km | 24,05 km | 19,91 km | 20,98 km \n",
    "| Ahunstic | 10,00 km | 23,21 km | 9,69 km | 21,68 km | 35,44 km |\n",
    "| Pointe-aux-Trembles | 17,67 km | 42,82 km | 28,37 km | 15,68 km | 18.19 km |\n",
    "| Vieux-Montréal | 2,16 km | 30,66 km | 15,18 km | 10,74 km | 35,60 km |\n",
    "| Verdun | 4,29 km | 29,58 km | 14,45 km | 12,10 km | 38,95 km |\n",
    "\n",
    "\n",
    "Ces distances ont été trouvé à l'aide de Google Map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculateMeanUsingDistance** mets dans une table la moyenne des surverses des stations les plus proches en fonction des ouvragres\n",
    "\n",
    "@params une table (ex: pcp_sum, pcp_max ...) \n",
    "\n",
    "@return une table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la quantité journalière de précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculateMeanUsingDistance(table)\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :StHubert], Assomption=table[:, :Assomption]);\n",
    "    S4240 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :StHubert], Assomption=table[:, :Assomption]);\n",
    "    S3260 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish]);\n",
    "    S4350_4380 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :Trudeau]);\n",
    "    S3350 = findMeanOfAllColumn(p);\n",
    "    \n",
    "    return DataFrame(date = table[:, :date],S4240=S4240[:name], S3260=S3260[:name],S4350_4380=S4350_4380[:name],S3350=S3350[:name] );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\"S3260\", \"S3350\",\"S4240\",\"S4350_4380\", \"S4350_4380\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = calculateMeanUsingDistance(pcp_sum)\n",
    "pcp_max = calculateMeanUsingDistance(pcp_max)\n",
    "pcp_sumBefore = calculateMeanUsingDistance(pcp_sumBefore)\n",
    "pcp_maxBefore = calculateMeanUsingDistance(pcp_maxBefore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à récupérer les valeurs de 8 tableaux pour les surverses telles que pour cela il faut specifier que c'est un tableau qui contient la moyenne et la variance pour chaque ouvrage dans l'ordre suivant : \n",
    "\n",
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"];\n",
    "\n",
    "**moyenneSumSurverses** : contient la moyenne des sommes des précipitations par jour où il y a eu une surverse. \n",
    "\n",
    "**moyenneMaxSurverses** : contient le maximum de précipitations par jour où il y a eu une surverse.\n",
    "\n",
    "**varianceSumSurverses** : contient la variance des sommes des précipitations par jour où il y a eu une surverse.\n",
    "\n",
    "**varianceMaxSurverses** : contient la variance des précipitations par jour où il y a eu une surverse.\n",
    "\n",
    "**moyenneSumNonSurverses** : contient la moyenne des sommes des précipitations par jour où il n’y a pas eu une surverse. \n",
    "\n",
    "**moyenneMaxNonSurverses** : contient le maximum de précipitations par jour où il n’y a pas eu une surverse.\n",
    "\n",
    "**varianceSumNonSurverses** : contient la variance des sommes des précipitations par jour où il n’y a pas eu une surverse.\n",
    "\n",
    "**varianceMaxNonSurverses** : contient la variance des précipitations des jours où il n’y a pas eu une surverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenneSumSurverses = Float64[]\n",
    "moyenneMaxSurverses = Float64[]\n",
    "varianceSumSurverses = Float64[];\n",
    "varianceMaxSurverses = Float64[];\n",
    "\n",
    "moyenneSumNonSurverses = Float64[]\n",
    "moyenneMaxNonSurverses = Float64[]\n",
    "varianceSumNonSurverses = Float64[]\n",
    "varianceMaxNonSurverses = Float64[]\n",
    "for j=1:size(filtervals,1)\n",
    "    dfSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==1, surverse_df)\n",
    "    dfNonSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==0, surverse_df)\n",
    "\n",
    "\n",
    "    moyenneSumSurverse = 0;\n",
    "    moyenneMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneSumSurverse += pcp_sum[ind,Symbol(table[j])]\n",
    "        \n",
    "        indmax = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneMaxSurverse +=  pcp_max[indmax,Symbol(table[j])]\n",
    "    end\n",
    "    moyenneSumSurverse = moyenneSumSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneSumSurverses, moyenneSumSurverse)\n",
    "    moyenneMaxSurverse = moyenneMaxSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneMaxSurverses, moyenneMaxSurverse)\n",
    "    \n",
    "    moyenneSumNonSurverse = 0;\n",
    "    moyenneMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneSumNonSurverse = moyenneSumNonSurverse +  pcp_sum[ind,Symbol(table[j])]\n",
    "        \n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneMaxNonSurverse = moyenneMaxNonSurverse +  pcp_max[ind,Symbol(table[j])]\n",
    "    end\n",
    "    moyenneSumNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(moyenneSumNonSurverses, moyenneSumNonSurverse)\n",
    "    moyenneMaxNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(moyenneMaxNonSurverses, moyenneMaxNonSurverse)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### maintenant la variance\n",
    "    varianceSumSurverse = 0;\n",
    "    varianceMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceSumSurverse += (pcp_sum[ind,Symbol(table[j])]-moyenneSumSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceMaxSurverse += (pcp_max[ind,Symbol(table[j])]-moyenneMaxSurverse)^2\n",
    "        \n",
    "       \n",
    "    end\n",
    "    varianceSumSurverse /= size(dfSurverse,1)\n",
    "    push!(varianceSumSurverses, varianceSumSurverse)\n",
    "    varianceMaxSurverse /= size(dfSurverse,1)\n",
    "    push!(varianceMaxSurverses, varianceMaxSurverse)\n",
    "\n",
    "    \n",
    "    varianceSumNonSurverse = 0;\n",
    "    varianceMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceSumNonSurverse += (pcp_sum[ind,Symbol(table[j])]-moyenneSumNonSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceMaxNonSurverse += (pcp_max[ind,Symbol(table[j])]-moyenneMaxNonSurverse)^2\n",
    "    \n",
    "    end\n",
    "    varianceSumNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(varianceSumNonSurverses, varianceSumNonSurverse)\n",
    "    varianceMaxNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(varianceMaxNonSurverses, varianceMaxNonSurverse) \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du fichier de prédictions pour soumettre sur Kaggle\n",
    "\n",
    "Dans ce cas-ci, nous prédirons une surverse avec une probabilité de 1/2 sans considérer aucune variable explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testfile = CSV.read(\"data/test.csv\")\n",
    "first(testfile,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idée rejetée\n",
    "Nous avons calculer la moyenne et la variance, pour chaque ouvrage, en considérant la somme et le maximum de la journée précedante. Et cela en prenant en consideration toute la journee antérieure ou juste toutes celles après 18h00 ou après 21h. En faisant les calculs, et en remettant sur kaggle nous avons remarqué que le score a légérement diminiué. Cela est probablement dû à la dependance entre les variables. Puisqu'en naive bayésienne, nous admettons l'hypothèse de dependance conditionnelle entre les variables. Cependant, dans ce cas la dependance ne pouvait pas être ignorée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#indx = findfirst(pcp_sumBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "# sumBefore= pcp_sumBefore[indx,Symbol(table[indproba])]\n",
    "\n",
    "#indx = findfirst(pcp_maxBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "#maxBefore = pcp_maxBefore[indx,Symbol(table[indproba])]\n",
    "#     \n",
    "#pSumBeforeSurverses = (1/sqrt(2*π*varianceSumBeforeSurverses[indproba])) - (1/2)*(((sumBefore-moyenneSumBeforeSurverses[indproba])^2)/varianceSumBeforeSurverses[indproba])\n",
    "#pSumBeforeSurverses = (1/sqrt(2*π*varianceSumBeforeSurverses[indproba]))*exp(- (1/2)*(((sumBefore-moyenneSumBeforeSurverses[indproba])^2)/varianceSumBeforeSurverses[indproba]))\n",
    "\n",
    "#pMaxBeforeSurverses = (1/sqrt(2*π*varianceMaxBeforeSurverses[indproba]))*exp(- (1/2)*(((maxBefore-moyenneMaxBeforeSurverses[indproba])^2)/varianceMaxBeforeSurverses[indproba]))\n",
    "  \n",
    "\n",
    "#pMaxBeforeSurverses = (1/sqrt(2*π*varianceMaxBeforeSurverses[indproba])) - (1/2)*(((maxBefore-moyenneMaxBeforeSurverses[indproba])^2)/varianceMaxBeforeSurverses[indproba])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On estime à l’aide du modèle gaussien et de la formule vu en cours les probabilités pSumSurverses et pMaxSurverses. Également, de la même manière pSumNoSurverses et pMaxNoSurverses.\n",
    "\n",
    "$ f_{(Y|\\mu, \\sigma^2)}(y) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp{-\\frac{1}{2\\sigma^2}(y-\\mu)^2} $\n",
    "\n",
    "**psurverse**: probabilité d’avoir une surverse\n",
    "\n",
    "**pSumSurverses**: probabilité d’obtenir cette somme des précipitations par jour sachant qu’il y a eu une surverse\n",
    "\n",
    "**pMaxSurverses**: probabilité d’obtenir cette valeur maximale pour les précipations par jour sachant qu’il y a eu une surverse\n",
    "\n",
    "**Pnonsurverse**: probabilité qu’il n’y ait pas de surverse\n",
    "\n",
    "**pSumNonSurverses**: probabilité d’obtenir cette somme des précipitations par jour sachant qu’il n’y a pas eu de surverse\n",
    "\n",
    "**pMaxNonSurverses**: probabilité d’obtenir cette valeur maximale pour les précipations par jour sachant qu’il n’y a pas eu de surverse\n",
    "\n",
    "Par la suite, on multiplie pSumSurverses par pMaxSurverses et pSumNoSurverses par pMaxNoSurverses, qu’on assigne respectivement aux variables pxSsurverse pxNoSsurverse.\n",
    "\n",
    "**pxSsurverse**: probabilité d’obtenir la somme des précipitations en étude ainsi que la valeur maximale de précipitations en question sachant qu’il y a eu une surverse. \n",
    "\n",
    "\n",
    "**pxSnonsurverse**: probabilité d’obtenir la somme des précipitations en étude ainsi que cette valeur maximale de précipitations en question sachant qu’il n’y a pas eu de surverse.\n",
    "\n",
    "On calcule finalement la probabilité de surverse ‘psurverse’ grâce au théorème de Bayes.\n",
    "\n",
    "$ P(E_{i}|A) = \\frac{P(A|E_{i})P(E_{i})}{P(A)} \n",
    "= \\frac{P(A|E_{i})P(E_{i})}{\\sum \\limits _{j=1}^{n}P(A|E_{j})P(E_{j})}$\n",
    "\n",
    "On a donc que $ pSurverse = \\frac{pxSsurverse * Psurverse}{pxSsurverse * Psurverse + pxSnonsurverse*Pnonsurverse} $\n",
    "\n",
    "\n",
    "On garde cette valeur si cette dernière est supérieure à 0,5 sinon elle est rejetée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverse = Int[]\n",
    "for i=1:size(testfile,1)\n",
    "    indproba = findfirst(filtervals[:] .== testfile[i,:NO_OUVRAGE])\n",
    "    ind = findfirst(pcp_sum[:,:date] .== testfile[i,:DATE])\n",
    "    sum = pcp_sum[ind,Symbol(table[indproba])]\n",
    "    ind = findfirst(pcp_max[:,:date] .== testfile[i,:DATE])\n",
    "    max = pcp_max[ind,Symbol(table[indproba])]\n",
    "      \n",
    "    indx = findfirst(pcp_sumBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "    sumBefore= pcp_sumBefore[indx,Symbol(table[indproba])]\n",
    "\n",
    "    indx = findfirst(pcp_maxBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "    maxBefore = pcp_maxBefore[indx,Symbol(table[indproba])]\n",
    "    Psurverse = n₁[indproba]/n[indproba]\n",
    "\n",
    "    pSumSurverses = (1/sqrt(2*π*varianceSumSurverses[indproba])) *exp(- (1/2)*(((sum-moyenneSumSurverses[indproba])^2)/varianceSumSurverses[indproba]))\n",
    "\n",
    "    pMaxSurverses = (1/sqrt(2*π*varianceMaxSurverses[indproba]))*exp(- (1/2)*(((max-moyenneMaxSurverses[indproba])^2)/varianceMaxSurverses[indproba]))\n",
    "    \n",
    "    Pnonsurverse = n₀[indproba]/n[indproba]\n",
    "\n",
    "    pSumNonSurverses = (1/sqrt(2*π*varianceSumNonSurverses[indproba]))*exp(- (1/2)*(((sum-moyenneSumNonSurverses[indproba])^2)/varianceSumNonSurverses[indproba]))\n",
    "    pMaxNonSurverses = (1/sqrt(2*π*varianceMaxNonSurverses[indproba]))*exp(- (1/2)*(((max-moyenneMaxNonSurverses[indproba])^2)/varianceMaxNonSurverses[indproba]))\n",
    "  \n",
    "    pxSsurverse = pSumSurverses * pMaxSurverses\n",
    "    \n",
    "    pxSnonsurverse = pSumNonSurverses * pMaxNonSurverses\n",
    "    \n",
    "  \n",
    "    psurverse = (pxSsurverse * Psurverse)/(pxSsurverse * Psurverse + pxSnonsurverse*Pnonsurverse)\n",
    "    isSurverse = psurverse>0.5\n",
    "    \n",
    "    #if isSurverse == 1\n",
    "        push!(surverse, isSurverse);\n",
    "\n",
    "end\n",
    "# Pour chacune des lignes du fichier test, comportant un ouvrage et une date, une prédiction est requise.\n",
    "# Dans ce cas-ci, utilisons une prédiction les plus naîve. \n",
    "# On prédit avec une chance sur deux qu'il y ait surverse, sans utiliser de variables explicatives\n",
    "\n",
    "\n",
    "\n",
    "# Création du fichier sampleSubmission.csv pour soumettre sur Kaggle\n",
    "ID = testfile[:,:NO_OUVRAGE].*\"_\".*string.(testfile[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=surverse)\n",
    "CSV.write(\"result.csv\",sampleSubmission)\n",
    "\n",
    "# Vous pouvez par la suite déposer le fichier sampleSubmission.csv sur Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace les schémas qui représentent les surverses et non surverses par rapport a la somme et au maximum. On remarque que les données ne semblent pas linéairement séparables. Ceci explique pourquoi notre modèle ne performe pas très bien. Nous suggérons d’utiliser l’algorithme SVM, ou les arbres de décision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures =[]\n",
    "for j=1:size(filtervals,1)\n",
    "    dfSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j] , surverse_df)\n",
    "    sums = DataFrame(SUM =Float64[])\n",
    "    maxs = DataFrame(MAX =Float64[])\n",
    "    surverse = DataFrame(surverse =Int64[])\n",
    "    for i=1:size(dfSurverse,1)\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        push!(sums, pcp_sum[ind,Symbol(table[j])])\n",
    "\n",
    "        indmax = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        push!(maxs, pcp_max[indmax, Symbol(table[j])])\n",
    "\n",
    "        push!(surverse, dfSurverse[i,:SURVERSE])\n",
    "    end\n",
    "\n",
    "    test = DataFrame(SUM = sums[:SUM], MAX =maxs[:MAX],SURVERSE= surverse[:surverse]);\n",
    "    p = plot(test, x=\"SUM\", y=\"MAX\",color=\"SURVERSE\",  Geom.point, Guide.title(filtervals[j]))\n",
    "    push!(figures, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
