{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "\n",
    "# Projet final : Débordement d'égouts\n",
    "### Équipe 17 : Elie Rouphael, Souhaila Mellouk, Thien-Kim Luu, Mourad Younes, Chararbsissy Lynn\n",
    "Remis le vendredi 20 décembre\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Le but de ce projet consiste à déterminer les caractéristiques des événements pluvieux susceptibles de générer des surverses sur le territoire de la Ville de Montréal. Il s'agit d'établir le lien entre les événements pluvieux et les surverses dues aux précipitations. On suppose que lorsqu'il n'y a pas de raison pour la surverse, il s'agit d'une surverse causée par les précipitations. Puisque nous nous intéresserons uniquement aux surverses occasionnées par les précipitations liquides, nous ne considérons que les mois de mai à octobre inclusivement.\n",
    "\n",
    "La description du projet est disponible à l'adresse suivante :\n",
    "https://www.kaggle.com/t/a238b752c33a41d9803c2cdde6bfc929\n",
    "\n",
    "Le fichier *surverse.csv* répertorie s'il y a surverse (1) ou non (0) au cours de la journée pour les 170 ouvrages de débordement de 2013 à 2018 pour les mois de mai à octobre (inclusivement). Des renseignements additionnels sur les données sont disponibles à l'adresse suivante :\n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/debordement\n",
    "\n",
    "\n",
    "Le fichier *precipitation.csv* contient les précipitations horaires en dixième de *mm* enregistrées à 5 stations pluviométriques de 2013 à 2019 :\n",
    "- McTavish (7024745)\n",
    "- Ste-Anne-de-Bellevue (702FHL8)\n",
    "- Montreal/Pierre Elliott Trudeau Intl (702S006)\n",
    "- Montreal/St-Hubert (7027329)\n",
    "- L’Assomption (7014160)\n",
    "\n",
    "Plus d'informations sur les précipitations sont disponibles à l'adresse suivante :\n",
    "\n",
    "https://climat.meteo.gc.ca/climate_data/hourly_data_f.html?hlyRange=2008-01-08%7C2019-11-12&dlyRange=2002-12-23%7C2019-11-12&mlyRange=%7C&StationID=30165&Prov=QC&urlExtension=_f.html&searchType=stnName&optLimit=yearRange&StartYear=1840&EndYear=2019&selRowPerPage=25&Line=17&searchMethod=contains&Month=11&Day=12&txtStationName=montreal&timeframe=1&Year=2019\n",
    "\n",
    "Le fichier *ouvrages-surverses.csv* contient différentes caractéristiques des ouvrages de débordement. \n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/ouvrage-surverse\n",
    "\n",
    "Le fichier *test.csv* contient les ouvrages et les jours pour lesquels vous devez prédire s'il y a eu surverse (true) ou non (false). Notez que l'on s'intéresse ici à 5 ouvrages de débordement localisés tout autour de l'Ile de Montréal :\n",
    "- 3260-01D dans Rivière-des-Prairies \n",
    "- 3350-07D dans Ahunstic \n",
    "- 4240-01D dans Pointe-aux-Trembles \n",
    "- 4350-01D dans le Vieux-Montréal \n",
    "- 4380-01D dans Verdun\n",
    "\n",
    "#### Remarque\n",
    "\n",
    "Dans le projet, on ne s'intéresse qu'aux surverses occasionnées par les précipitations. On ignore les surverses occasionnées par \n",
    "- fonte de neige (F)\n",
    "- travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)\n",
    "\n",
    "On suppose que lorsqu'il n'y a pas de raison pour la surverse, il s'agit d'une surverse causée par les précipitations. Puisque Nous nous intéresserons uniquement aux surverses occasionnées par les précipitations liquides, nous ne considérons que les mois de mai à octobre inclusivement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/surverses.csv\",missingstring=\"-99999\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.DATE) > 4, data) \n",
    "data = filter(row -> month(row.DATE) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data[:,:RAISON],\"Inconnue\")\n",
    "data[!,:RAISON] = raison\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>176,667 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr><tr><th>6</th><td>0642-01D</td><td>2013-05-06</td><td>0</td></tr><tr><th>7</th><td>0642-01D</td><td>2013-05-07</td><td>0</td></tr><tr><th>8</th><td>0642-01D</td><td>2013-05-08</td><td>0</td></tr><tr><th>9</th><td>0642-01D</td><td>2013-05-09</td><td>0</td></tr><tr><th>10</th><td>0642-01D</td><td>2013-05-10</td><td>0</td></tr><tr><th>11</th><td>0642-01D</td><td>2013-05-11</td><td>0</td></tr><tr><th>12</th><td>0642-01D</td><td>2013-05-12</td><td>0</td></tr><tr><th>13</th><td>0642-01D</td><td>2013-05-13</td><td>0</td></tr><tr><th>14</th><td>0642-01D</td><td>2013-05-14</td><td>0</td></tr><tr><th>15</th><td>0642-01D</td><td>2013-05-15</td><td>0</td></tr><tr><th>16</th><td>0642-01D</td><td>2013-05-16</td><td>0</td></tr><tr><th>17</th><td>0642-01D</td><td>2013-05-17</td><td>0</td></tr><tr><th>18</th><td>0642-01D</td><td>2013-05-18</td><td>0</td></tr><tr><th>19</th><td>0642-01D</td><td>2013-05-19</td><td>0</td></tr><tr><th>20</th><td>0642-01D</td><td>2013-05-20</td><td>0</td></tr><tr><th>21</th><td>0642-01D</td><td>2013-05-21</td><td>0</td></tr><tr><th>22</th><td>0642-01D</td><td>2013-05-22</td><td>0</td></tr><tr><th>23</th><td>0642-01D</td><td>2013-05-23</td><td>0</td></tr><tr><th>24</th><td>0642-01D</td><td>2013-05-24</td><td>0</td></tr><tr><th>25</th><td>0642-01D</td><td>2013-05-25</td><td>0</td></tr><tr><th>26</th><td>0642-01D</td><td>2013-05-26</td><td>0</td></tr><tr><th>27</th><td>0642-01D</td><td>2013-05-27</td><td>0</td></tr><tr><th>28</th><td>0642-01D</td><td>2013-05-28</td><td>0</td></tr><tr><th>29</th><td>0642-01D</td><td>2013-05-29</td><td>0</td></tr><tr><th>30</th><td>0642-01D</td><td>2013-05-30</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\t6 & 0642-01D & 2013-05-06 & 0 \\\\\n",
       "\t7 & 0642-01D & 2013-05-07 & 0 \\\\\n",
       "\t8 & 0642-01D & 2013-05-08 & 0 \\\\\n",
       "\t9 & 0642-01D & 2013-05-09 & 0 \\\\\n",
       "\t10 & 0642-01D & 2013-05-10 & 0 \\\\\n",
       "\t11 & 0642-01D & 2013-05-11 & 0 \\\\\n",
       "\t12 & 0642-01D & 2013-05-12 & 0 \\\\\n",
       "\t13 & 0642-01D & 2013-05-13 & 0 \\\\\n",
       "\t14 & 0642-01D & 2013-05-14 & 0 \\\\\n",
       "\t15 & 0642-01D & 2013-05-15 & 0 \\\\\n",
       "\t16 & 0642-01D & 2013-05-16 & 0 \\\\\n",
       "\t17 & 0642-01D & 2013-05-17 & 0 \\\\\n",
       "\t18 & 0642-01D & 2013-05-18 & 0 \\\\\n",
       "\t19 & 0642-01D & 2013-05-19 & 0 \\\\\n",
       "\t20 & 0642-01D & 2013-05-20 & 0 \\\\\n",
       "\t21 & 0642-01D & 2013-05-21 & 0 \\\\\n",
       "\t22 & 0642-01D & 2013-05-22 & 0 \\\\\n",
       "\t23 & 0642-01D & 2013-05-23 & 0 \\\\\n",
       "\t24 & 0642-01D & 2013-05-24 & 0 \\\\\n",
       "\t25 & 0642-01D & 2013-05-25 & 0 \\\\\n",
       "\t26 & 0642-01D & 2013-05-26 & 0 \\\\\n",
       "\t27 & 0642-01D & 2013-05-27 & 0 \\\\\n",
       "\t28 & 0642-01D & 2013-05-28 & 0 \\\\\n",
       "\t29 & 0642-01D & 2013-05-29 & 0 \\\\\n",
       "\t30 & 0642-01D & 2013-05-30 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "176667×3 DataFrame\n",
       "│ Row    │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│        │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├────────┼────────────┼────────────┼──────────┤\n",
       "│ 1      │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2      │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3      │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4      │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5      │ 0642-01D   │ 2013-05-05 │ 0        │\n",
       "│ 6      │ 0642-01D   │ 2013-05-06 │ 0        │\n",
       "│ 7      │ 0642-01D   │ 2013-05-07 │ 0        │\n",
       "│ 8      │ 0642-01D   │ 2013-05-08 │ 0        │\n",
       "│ 9      │ 0642-01D   │ 2013-05-09 │ 0        │\n",
       "│ 10     │ 0642-01D   │ 2013-05-10 │ 0        │\n",
       "⋮\n",
       "│ 176657 │ 4560-02D   │ 2018-10-21 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176658 │ 4560-02D   │ 2018-10-22 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176659 │ 4560-02D   │ 2018-10-23 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176660 │ 4560-02D   │ 2018-10-24 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176661 │ 4560-02D   │ 2018-10-25 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176662 │ 4560-02D   │ 2018-10-26 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176663 │ 4560-02D   │ 2018-10-27 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176664 │ 4560-02D   │ 2018-10-28 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176665 │ 4560-02D   │ 2018-10-29 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176666 │ 4560-02D   │ 2018-10-30 │ \u001b[90mmissing\u001b[39m  │\n",
       "│ 176667 │ 4560-02D   │ 2018-10-31 │ \u001b[90mmissing\u001b[39m  │"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data) \n",
    "select!(data, [:NO_OUVRAGE, :DATE, :SURVERSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverse_df = dropmissing(data, disallowmissing=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[508]:1\n",
      "└ @ Core In[508]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[508]:2\n",
      "└ @ Core In[508]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 161098"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n₁ = sum(x->x==1, surverse_df[:SURVERSE], dims=1) \n",
    "n₀ = sum(x->x==0, surverse_df[:SURVERSE], dims=1) \n",
    "n = n₀ + n₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"]\n",
    "surverse_df1 = filter(row-> row.NO_OUVRAGE == filtervals[1], surverse_df)\n",
    "surverse_df2 = filter(row-> row.NO_OUVRAGE == filtervals[2], surverse_df)\n",
    "surverse_df3 = filter(row-> row.NO_OUVRAGE == filtervals[3], surverse_df)\n",
    "surverse_df4 = filter(row-> row.NO_OUVRAGE == filtervals[4], surverse_df)\n",
    "surverse_df5 = filter(row-> row.NO_OUVRAGE == filtervals[5], surverse_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Int64,1}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### on prend pour chaque ouvrage le nombre de fois ou il a eu surver et non\n",
    "n₁ = Int64[]\n",
    "n₀  = Int64[]\n",
    "n  = Int64[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findSurverseCount (generic function with 1 method)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function findSurverseCount(surverse_df1)\n",
    "    n1₁ = sum(x->x==1, surverse_df1, dims=1) \n",
    "    push!(n₁, n1₁[1])\n",
    "    n1₀ = sum(x->x==0, surverse_df1, dims=1)  \n",
    "    push!(n₀, n1₀[1])\n",
    "    n1= n1₁[1] + n1₀[1]\n",
    "    push!(n, n1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[512]:1\n",
      "└ @ Core In[512]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[512]:2\n",
      "└ @ Core In[512]:2\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[512]:3\n",
      "└ @ Core In[512]:3\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[512]:4\n",
      "└ @ Core In[512]:4\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[512]:5\n",
      "└ @ Core In[512]:5\n"
     ]
    }
   ],
   "source": [
    "findSurverseCount(surverse_df1[:SURVERSE]);\n",
    "findSurverseCount(surverse_df2[:SURVERSE]);\n",
    "findSurverseCount(surverse_df3[:SURVERSE]);\n",
    "findSurverseCount(surverse_df4[:SURVERSE]);\n",
    "findSurverseCount(surverse_df5[:SURVERSE]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-01-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-01-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-01-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-01-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-01-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-01-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-01-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-01-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-01-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-01-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-01-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-01-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-01-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-01-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-01-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databefore = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(databefore, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(databefore,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-01-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-01-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-01-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-01-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-01-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-01-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-01-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-01-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-01-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-01-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-01-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-01-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-01-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-01-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-01-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter(row -> month(row.date) > 4, data) \n",
    "data = filter(row -> month(row.date) < 11, data) \n",
    "databefore = filter(row -> month(row.date) > 3, databefore) \n",
    "databefore = filter(row -> month(row.date) < 11, databefore) \n",
    "databefore = filter(row -> row.heure >= 19, databefore) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fillWithMean (generic function with 1 method)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fillWithMean(table)\n",
    "    \n",
    "    for j=1:size(table,1)\n",
    "        means = 0\n",
    "        sum = 0\n",
    "        alo = names(table)\n",
    "        for col in alo\n",
    "            if col != alo[1]\n",
    "                if !ismissing(table[j, col]) \n",
    "                    sum = sum +1\n",
    "                    means = means + table[j, col]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        if sum != 0\n",
    "            means = means / sum\n",
    "        end\n",
    "        for col in alo\n",
    "            if ismissing(table[j, col]) && col != alo[1]\n",
    "                tests = floor(means)\n",
    "                table[j, col] = floor(tests)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillWithMean(data)\n",
    "fillWithMean(databefore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(data, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum);\n",
    "first(pcp_sum ,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(data, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sumBefore = by(databefore, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum);\n",
    "first(pcp_sum ,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_maxBefore = by(databefore, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire\n",
    "\n",
    "Cette section consitue une analyse exploratoire superficielle permettant de voir s'il existe un lien entre les précipitations et les surverses.\n",
    "\n",
    "Prenons arbitrairement l'ouvrage de débordement près du Bota-Bota (4350-01D). La station météorologique la plus proche est McTavish. Prenons deux variables explicatives simple :\n",
    "- la somme journalière des précipitations\n",
    "- le taux horaire maximum journalier de précipitations\n",
    "\n",
    "#### Calcul de la quantité journalière de précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findMeanOfAllColumn (generic function with 1 method)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findMeanOfAllColumn(table)\n",
    "    p = DataFrame(name =Float64[])\n",
    "    for j=1:size(table,1)\n",
    "        alo = names(table)\n",
    "        means = 0\n",
    "        sum = 0\n",
    "        for col in alo\n",
    "            if col != alo[1]\n",
    "                if !ismissing(table[j, col]) \n",
    "                    sum = sum +1\n",
    "                    means = means + table[j, col]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(p, means/sum)\n",
    "    end\n",
    "    table = DataFrame(date = table[:date]; name =p[:name]);\n",
    "    return table\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pcp_sum_before.csv\""
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"pcp_max_before.csv\",pcp_max)\n",
    "CSV.write(\"pcp_sum_before.csv\",pcp_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inclusion dans un dataframe de ces deux variables explicatives potentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculateMeanUsingDistance (generic function with 1 method)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculateMeanUsingDistance(table)\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :StHubert], Assomption=table[:, :Assomption]);\n",
    "    S4240 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :StHubert], Assomption=table[:, :Assomption]);\n",
    "    S3260 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish]);\n",
    "    S4350_4380 = findMeanOfAllColumn(p);\n",
    "    p = DataFrame(date = table[:, :date],McTavish =table[:, :McTavish],StHubert=table[:, :Trudeau]);\n",
    "    S3350 = findMeanOfAllColumn(p);\n",
    "    \n",
    "    return DataFrame(date = table[:, :date],S4240=S4240[:name], S3260=S3260[:name],S4350_4380=S4350_4380[:name],S3350=S3350[:name] );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = findMeanOfAllColumn(::DataFrame) at In[522]:17\n",
      "└ @ Main .\\In[522]:17\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = findMeanOfAllColumn(::DataFrame) at In[522]:17\n",
      "└ @ Main .\\In[522]:17\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = calculateMeanUsingDistance(::DataFrame) at In[524]:11\n",
      "└ @ Main .\\In[524]:11\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = calculateMeanUsingDistance(::DataFrame) at In[524]:11\n",
      "└ @ Main .\\In[524]:11\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = calculateMeanUsingDistance(::DataFrame) at In[524]:11\n",
      "└ @ Main .\\In[524]:11\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = calculateMeanUsingDistance(::DataFrame) at In[524]:11\n",
      "└ @ Main .\\In[524]:11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>S4240</th><th>S3260</th><th>S4350_4380</th><th>S3350</th></tr><tr><th></th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>1,498 rows × 5 columns</p><tr><th>1</th><td>2013-04-01</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>2013-04-02</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>2013-04-03</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>2013-04-04</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2013-04-05</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>2013-04-06</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>2013-04-07</td><td>9.33333</td><td>9.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>2013-04-08</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>2013-04-09</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>2013-04-10</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>2013-04-11</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>2013-04-12</td><td>18.0</td><td>18.0</td><td>20.0</td><td>16.5</td></tr><tr><th>13</th><td>2013-04-13</td><td>9.33333</td><td>9.33333</td><td>10.0</td><td>5.0</td></tr><tr><th>14</th><td>2013-04-14</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>2013-04-15</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>2013-04-16</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>2013-04-17</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>2013-04-18</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>2013-04-19</td><td>26.0</td><td>26.0</td><td>31.0</td><td>27.5</td></tr><tr><th>20</th><td>2013-04-20</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>2013-04-21</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>2013-04-22</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>2013-04-23</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>2013-04-24</td><td>18.6667</td><td>18.6667</td><td>20.0</td><td>19.0</td></tr><tr><th>25</th><td>2013-04-25</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>2013-04-26</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>2013-04-27</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>2013-04-28</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>2013-04-29</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>2013-04-30</td><td>1.33333</td><td>1.33333</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& date & S4240 & S3260 & S4350\\_4380 & S3350\\\\\n",
       "\t\\hline\n",
       "\t& Date & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-04-01 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t2 & 2013-04-02 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t3 & 2013-04-03 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t4 & 2013-04-04 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t5 & 2013-04-05 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t6 & 2013-04-06 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t7 & 2013-04-07 & 9.33333 & 9.33333 & 0.0 & 0.0 \\\\\n",
       "\t8 & 2013-04-08 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t9 & 2013-04-09 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t10 & 2013-04-10 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t11 & 2013-04-11 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t12 & 2013-04-12 & 18.0 & 18.0 & 20.0 & 16.5 \\\\\n",
       "\t13 & 2013-04-13 & 9.33333 & 9.33333 & 10.0 & 5.0 \\\\\n",
       "\t14 & 2013-04-14 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t15 & 2013-04-15 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t16 & 2013-04-16 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t17 & 2013-04-17 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t18 & 2013-04-18 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t19 & 2013-04-19 & 26.0 & 26.0 & 31.0 & 27.5 \\\\\n",
       "\t20 & 2013-04-20 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t21 & 2013-04-21 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t22 & 2013-04-22 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t23 & 2013-04-23 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t24 & 2013-04-24 & 18.6667 & 18.6667 & 20.0 & 19.0 \\\\\n",
       "\t25 & 2013-04-25 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t26 & 2013-04-26 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t27 & 2013-04-27 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t28 & 2013-04-28 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t29 & 2013-04-29 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t30 & 2013-04-30 & 1.33333 & 1.33333 & 0.0 & 0.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1498×5 DataFrame\n",
       "│ Row  │ date       │ S4240   │ S3260   │ S4350_4380 │ S3350   │\n",
       "│      │ \u001b[90mDate\u001b[39m       │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m │\n",
       "├──────┼────────────┼─────────┼─────────┼────────────┼─────────┤\n",
       "│ 1    │ 2013-04-01 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 2    │ 2013-04-02 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 3    │ 2013-04-03 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 4    │ 2013-04-04 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 5    │ 2013-04-05 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 6    │ 2013-04-06 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 7    │ 2013-04-07 │ 9.33333 │ 9.33333 │ 0.0        │ 0.0     │\n",
       "│ 8    │ 2013-04-08 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 9    │ 2013-04-09 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "│ 10   │ 2013-04-10 │ 1.33333 │ 1.33333 │ 0.0        │ 0.0     │\n",
       "⋮\n",
       "│ 1488 │ 2019-10-21 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1489 │ 2019-10-22 │ 30.6667 │ 30.6667 │ 31.0       │ 42.0    │\n",
       "│ 1490 │ 2019-10-23 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1491 │ 2019-10-24 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1492 │ 2019-10-25 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1493 │ 2019-10-26 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1494 │ 2019-10-27 │ 17.3333 │ 17.3333 │ 22.0       │ 16.5    │\n",
       "│ 1495 │ 2019-10-28 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1496 │ 2019-10-29 │ 1.66667 │ 1.66667 │ 0.0        │ 0.0     │\n",
       "│ 1497 │ 2019-10-30 │ 23.0    │ 23.0    │ 23.0       │ 23.0    │\n",
       "│ 1498 │ 2019-10-31 │ 23.0    │ 23.0    │ 23.0       │ 23.0    │"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_sum = calculateMeanUsingDistance(pcp_sum)\n",
    "pcp_max = calculateMeanUsingDistance(pcp_max)\n",
    "pcp_sumBefore = calculateMeanUsingDistance(pcp_sumBefore)\n",
    "pcp_maxBefore = calculateMeanUsingDistance(pcp_maxBefore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{String,1}:\n",
       " \"S3260\"     \n",
       " \"S3350\"     \n",
       " \"S4240\"     \n",
       " \"S4350_4380\"\n",
       " \"S4350_4380\""
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtervals = [\"3260-01D\"; \"3350-07D\"; \"4240-01D\"; \"4350-01D\"; \"4380-01D\"]\n",
    "table = [\"S3260\", \"S3350\",\"S4240\",\"S4350_4380\", \"S4350_4380\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenneSumSurverses = Float64[]\n",
    "moyenneMaxSurverses = Float64[]\n",
    "varianceSumSurverses = Float64[];\n",
    "varianceMaxSurverses = Float64[];\n",
    "\n",
    "moyenneSumNonSurverses = Float64[]\n",
    "moyenneMaxNonSurverses = Float64[]\n",
    "varianceSumNonSurverses = Float64[]\n",
    "varianceMaxNonSurverses = Float64[]\n",
    "for j=1:size(filtervals,1)\n",
    "    dfSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==1, surverse_df)\n",
    "    dfNonSurverse = filter(row -> row.NO_OUVRAGE == filtervals[j]  && row.SURVERSE ==0, surverse_df)\n",
    "\n",
    "\n",
    "    moyenneSumSurverse = 0;\n",
    "    moyenneMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneSumSurverse += pcp_sum[ind,Symbol(table[j])]\n",
    "        \n",
    "        indmax = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        moyenneMaxSurverse +=  pcp_max[indmax,Symbol(table[j])]\n",
    "    end\n",
    "    moyenneSumSurverse = moyenneSumSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneSumSurverses, moyenneSumSurverse)\n",
    "    moyenneMaxSurverse = moyenneMaxSurverse / size(dfSurverse,1)\n",
    "    push!(moyenneMaxSurverses, moyenneMaxSurverse)\n",
    "    \n",
    "    moyenneSumNonSurverse = 0;\n",
    "    moyenneMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneSumNonSurverse = moyenneSumNonSurverse +  pcp_sum[ind,Symbol(table[j])]\n",
    "        \n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        moyenneMaxNonSurverse = moyenneMaxNonSurverse +  pcp_max[ind,Symbol(table[j])]\n",
    "    end\n",
    "    moyenneSumNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(moyenneSumNonSurverses, moyenneSumNonSurverse)\n",
    "    moyenneMaxNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(moyenneMaxNonSurverses, moyenneMaxNonSurverse)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### maintenant la variance\n",
    "    varianceSumSurverse = 0;\n",
    "    varianceMaxSurverse = 0;\n",
    "    for i=1:size(dfSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceSumSurverse += (pcp_sum[ind,Symbol(table[j])]-moyenneSumSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfSurverse[i,:DATE])\n",
    "        varianceMaxSurverse += (pcp_max[ind,Symbol(table[j])]-moyenneMaxSurverse)^2\n",
    "        \n",
    "       \n",
    "    end\n",
    "    varianceSumSurverse /= size(dfSurverse,1)\n",
    "    push!(varianceSumSurverses, varianceSumSurverse)\n",
    "    varianceMaxSurverse /= size(dfSurverse,1)\n",
    "    push!(varianceMaxSurverses, varianceMaxSurverse)\n",
    "\n",
    "    \n",
    "    varianceSumNonSurverse = 0;\n",
    "    varianceMaxNonSurverse = 0;\n",
    "    for i=1:size(dfNonSurverse,1)\n",
    "\n",
    "        ind = findfirst(pcp_sum[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceSumNonSurverse += (pcp_sum[ind,Symbol(table[j])]-moyenneSumNonSurverse)^2\n",
    "\n",
    "        ind = findfirst(pcp_max[:,:date] .== dfNonSurverse[i,:DATE])\n",
    "        varianceMaxNonSurverse += (pcp_max[ind,Symbol(table[j])]-moyenneMaxNonSurverse)^2\n",
    "    \n",
    "    end\n",
    "    varianceSumNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(varianceSumNonSurverses, varianceSumNonSurverse)\n",
    "    varianceMaxNonSurverse /= size(dfNonSurverse,1)\n",
    "    push!(varianceMaxNonSurverses, varianceMaxNonSurverse) \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que la somme des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que le maximum journalier des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du fichier de prédictions pour soumettre sur Kaggle\n",
    "\n",
    "Dans ce cas-ci, nous prédirons une surverse avec une probabilité de 1/2 sans considérer aucune variable explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th></tr><tr><th></th><th>String</th><th>Date</th></tr></thead><tbody><p>5 rows × 2 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& NO\\_OUVRAGE & DATE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×2 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼────────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "testfile = CSV.read(\"data/test.csv\")\n",
    "first(testfile,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#indx = findfirst(pcp_sumBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "# sumBefore= pcp_sumBefore[indx,Symbol(table[indproba])]\n",
    "\n",
    "#indx = findfirst(pcp_maxBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "#maxBefore = pcp_maxBefore[indx,Symbol(table[indproba])]\n",
    "#     \n",
    "#pSumBeforeSurverses = (1/sqrt(2*π*varianceSumBeforeSurverses[indproba])) - (1/2)*(((sumBefore-moyenneSumBeforeSurverses[indproba])^2)/varianceSumBeforeSurverses[indproba])\n",
    " pSumBeforeSurverses = (1/sqrt(2*π*varianceSumBeforeSurverses[indproba]))*exp(- (1/2)*(((sumBefore-moyenneSumBeforeSurverses[indproba])^2)/varianceSumBeforeSurverses[indproba]))\n",
    "\n",
    "pMaxBeforeSurverses = (1/sqrt(2*π*varianceMaxBeforeSurverses[indproba]))*exp(- (1/2)*(((maxBefore-moyenneMaxBeforeSurverses[indproba])^2)/varianceMaxBeforeSurverses[indproba]))\n",
    "  \n",
    "\n",
    "#pMaxBeforeSurverses = (1/sqrt(2*π*varianceMaxBeforeSurverses[indproba])) - (1/2)*(((maxBefore-moyenneMaxBeforeSurverses[indproba])^2)/varianceMaxBeforeSurverses[indproba])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abel6.csv\""
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surverse = Int[]\n",
    "for i=1:size(testfile,1)\n",
    "    indproba = findfirst(filtervals[:] .== testfile[i,:NO_OUVRAGE])\n",
    "    ind = findfirst(pcp_sum[:,:date] .== testfile[i,:DATE])\n",
    "    sum = pcp_sum[ind,Symbol(table[indproba])]\n",
    "    ind = findfirst(pcp_max[:,:date] .== testfile[i,:DATE])\n",
    "    max = pcp_max[ind,Symbol(table[indproba])]\n",
    "      \n",
    "    indx = findfirst(pcp_sumBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "    sumBefore= pcp_sumBefore[indx,Symbol(table[indproba])]\n",
    "\n",
    "    indx = findfirst(pcp_maxBefore[:,:date] .== (testfile[i,:DATE]-Dates.Day(1)))\n",
    "    maxBefore = pcp_maxBefore[indx,Symbol(table[indproba])]\n",
    "    Psurverse = n₁[indproba]/n[indproba]\n",
    "\n",
    "    pSumSurverses = (1/sqrt(2*π*varianceSumSurverses[indproba])) *exp(- (1/2)*(((sum-moyenneSumSurverses[indproba])^2)/varianceSumSurverses[indproba]))\n",
    "\n",
    "    pMaxSurverses = (1/sqrt(2*π*varianceMaxSurverses[indproba]))*exp(- (1/2)*(((max-moyenneMaxSurverses[indproba])^2)/varianceMaxSurverses[indproba]))\n",
    "    \n",
    "    Pnonsurverse = n₀[indproba]/n[indproba]\n",
    "\n",
    "    pSumNonSurverses = (1/sqrt(2*π*varianceSumNonSurverses[indproba]))*exp(- (1/2)*(((sum-moyenneSumNonSurverses[indproba])^2)/varianceSumNonSurverses[indproba]))\n",
    "    pMaxNonSurverses = (1/sqrt(2*π*varianceMaxNonSurverses[indproba]))*exp(- (1/2)*(((max-moyenneMaxNonSurverses[indproba])^2)/varianceMaxNonSurverses[indproba]))\n",
    "  \n",
    "    pxSsurverse = pSumSurverses * pMaxSurverses\n",
    "    \n",
    "    pxSnonsurverse = pSumNonSurverses * pMaxNonSurverses\n",
    "    \n",
    "  \n",
    "    psurverse = (pxSsurverse * Psurverse)/(pxSsurverse * Psurverse + pxSnonsurverse*Pnonsurverse)\n",
    "    isSurverse = psurverse>0.5\n",
    "    \n",
    "    #if isSurverse == 1\n",
    "        push!(surverse, isSurverse);\n",
    "   # else\n",
    "    #     pxSsurverse = pSumSurverses * pMaxSurverses *pSumBeforeSurverses\n",
    "    \n",
    "    #    pxSnonsurverse = pSumNonSurverses * pMaxNonSurverses * pSumBeforeNonSurverses\n",
    "    \n",
    "  \n",
    "    #    psurverse = (pxSsurverse * Psurverse)/(pxSsurverse * Psurverse + pxSnonsurverse*Pnonsurverse)\n",
    "    #    isSurverse = psurverse>0.5 && sumBefore!=0 && sum !=0\n",
    "    #    push!(surverse, isSurverse);\n",
    "    #end\n",
    "end\n",
    "# Pour chacune des lignes du fichier test, comportant un ouvrage et une date, une prédiction est requise.\n",
    "# Dans ce cas-ci, utilisons une prédiction les plus naîve. \n",
    "# On prédit avec une chance sur deux qu'il y ait surverse, sans utiliser de variables explicatives\n",
    "\n",
    "\n",
    "\n",
    "# Création du fichier sampleSubmission.csv pour soumettre sur Kaggle\n",
    "ID = testfile[:,:NO_OUVRAGE].*\"_\".*string.(testfile[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=surverse)\n",
    "CSV.write(\"result.csv\",sampleSubmission)\n",
    "\n",
    "# Vous pouvez par la suite déposer le fichier sampleSubmission.csv sur Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
